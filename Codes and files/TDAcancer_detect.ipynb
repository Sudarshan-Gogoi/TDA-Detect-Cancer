{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3ad4c9-74f5-4524-8261-08887d947954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDAcancer_detect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d298a05-57f0-4b48-8b03-149b5a91e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f17cf0-a0c7-43c7-9299-e9d448ce101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Normal Positive': 36, 'Breast Positive': 77, 'Colorectum Positive': 182, 'Esophagus Positive': 25, 'Liver Positive': 29, 'Lung Positive': 47, 'Ovary Positive': 41, 'Pancreas Positive': 42, 'Stomach Positive': 55, 'Total Positive Cancers': 498}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gudhi\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def TDAcancer_detect_1(file_path, biomarkers, random_patient_range, control_data_range, regression_threshold, distance_threshold, max_life_range_threshold_upper, max_life_range_threshold_lower, tumor_types):\n",
    "    # Step 1: Load the Excel data\n",
    "    df_1 = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    df_2 = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Step 2: Select the biomarkers (user-defined)\n",
    "    df_1 = df_1[biomarkers].iloc[:59]  # Fixed dataset of 59 normal patients\n",
    "    df_2 = df_2[biomarkers]\n",
    "\n",
    "    # Step 3: Initialize list for topological features\n",
    "    data_list = []\n",
    "\n",
    "    # Step 4: Loop through rows 60 to random_patient_range and perform TDA analysis\n",
    "    for index in range(60, random_patient_range + 1):\n",
    "        row_to_add = df_2.iloc[[index]]\n",
    "        df_new = pd.concat([df_1, row_to_add], ignore_index=True)\n",
    "\n",
    "        # Log normalize numeric columns\n",
    "        numeric_cols = df_new.select_dtypes(include=[np.number]).columns\n",
    "        df_new[numeric_cols] = np.log(df_new[numeric_cols])\n",
    "\n",
    "        # Pearson correlation matrix\n",
    "        corr_matrix = np.corrcoef(df_new.values, rowvar=False)\n",
    "        distance_matrix = 1 - np.abs(pd.DataFrame(corr_matrix).values)\n",
    "\n",
    "        # Compute persistence homology\n",
    "        rips_complex = gudhi.RipsComplex(distance_matrix=distance_matrix)\n",
    "        simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "        persistence = simplex_tree.persistence()\n",
    "\n",
    "        # Extract 1D and 0D hole statistics\n",
    "        finite_persistence = [(dim, (birth, death)) for dim, (birth, death) in persistence if death != float('inf')]\n",
    "        one_dim_holes = [(birth, death) for dim, (birth, death) in finite_persistence if dim == 1]\n",
    "        zero_dim_holes = [(birth, death) for dim, (birth, death) in finite_persistence if dim == 0]\n",
    "\n",
    "        max_life_range_1D = max((death - birth for birth, death in one_dim_holes), default=0)\n",
    "        avg_birth_1D = np.mean([birth for birth, _ in one_dim_holes]) if one_dim_holes else 0\n",
    "        avg_death_1D = np.mean([death for _, death in one_dim_holes]) if one_dim_holes else 0\n",
    "        num_one_dim_holes = len(one_dim_holes)\n",
    "\n",
    "        min_life_range_0D = min((death - birth for birth, death in zero_dim_holes), default=0)\n",
    "        max_life_range_0D = max((death - birth for birth, death in zero_dim_holes), default=0)\n",
    "        avg_death_0D = np.mean([death for _, death in zero_dim_holes]) if zero_dim_holes else 0\n",
    "        num_zero_dim_holes = len(zero_dim_holes) + 1\n",
    "        range_death_0D = max([death for _, death in zero_dim_holes], default=0) - min([death for _, death in zero_dim_holes], default=0)\n",
    "        median_death_0D = np.median([death for _, death in zero_dim_holes]) if zero_dim_holes else 0\n",
    "        std_death_0D = np.std([death for _, death in zero_dim_holes]) if zero_dim_holes else 0\n",
    "\n",
    "        # Store feature vector\n",
    "        data = {\n",
    "            \"0-Dim Hole Min Life Range\": [min_life_range_0D],\n",
    "            \"0-Dim Hole Max Life Range\": [max_life_range_0D],\n",
    "            \"Range_Death_0D\": [range_death_0D],\n",
    "            \"Num_0D_Holes\": [num_zero_dim_holes],\n",
    "            \"Median_Death_0D\": [median_death_0D],\n",
    "            \"Std_Death_0D\": [std_death_0D],\n",
    "            \"Avg_Death_0D\": [avg_death_0D],\n",
    "            \"Average Birth (1D)\": [avg_birth_1D],\n",
    "            \"Average Death (1D)\": [avg_death_1D],\n",
    "            \"1-Dim Hole Max Life Range\": [max_life_range_1D],\n",
    "            \"Number of 1-Dimensional Holes\": [num_one_dim_holes]\n",
    "        }\n",
    "        df = pd.DataFrame(data, index=[f\"P_{index}\"])\n",
    "        data_list.append(df)\n",
    "\n",
    "    # Step 5: Save results to CSV\n",
    "    final_df = pd.concat(data_list)\n",
    "\n",
    "    # Add Patient ID, Sample ID, Cohort, and AJCC Stage to the final CSV\n",
    "    additional_columns = ['Patient ID #', 'Cohort', 'AJCC Stage']\n",
    "    df_clinical = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    df_additional_info = df_clinical[additional_columns].iloc[60:random_patient_range + 1]  # Corresponding rows to additional patients\n",
    "    additional_info_index = [f\"P_{i}\" for i in range(60, random_patient_range + 1)]\n",
    "    df_additional_info.index = additional_info_index\n",
    "\n",
    "    # Merge the additional columns with the TDA results\n",
    "    df_combined = pd.concat([df_additional_info, final_df], axis=1)\n",
    "\n",
    "    # Get directory from original file path and create consistent output filename\n",
    "    directory = os.path.dirname(file_path)\n",
    "    csv_file_path = os.path.join(directory, \"Clinical cancer data_features.csv\")\n",
    "    df_combined.to_csv(csv_file_path, index=True)\n",
    "\n",
    "    # Step 6: Train Linear Regression Model\n",
    "    new_data = pd.read_csv(csv_file_path)\n",
    "    control_data = new_data.iloc[:control_data_range]  # User-defined control data range\n",
    "\n",
    "    X = control_data[['0-Dim Hole Min Life Range', '0-Dim Hole Max Life Range', 'Median_Death_0D', 'Std_Death_0D']]\n",
    "    y = control_data['Avg_Death_0D']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "\n",
    "    # Step 7: Predict and Analyze\n",
    "    def predict_Avg_Death_0D(row):\n",
    "        return np.dot(model.coef_, [row[col] for col in X.columns]) + model.intercept_\n",
    "\n",
    "    new_data['Predicted Avg_Death_0D'] = new_data.apply(predict_Avg_Death_0D, axis=1)\n",
    "    new_data['Difference'] = new_data['Avg_Death_0D'] - new_data['Predicted Avg_Death_0D']\n",
    "    new_data['Regression Difference Percentage'] = abs(new_data['Difference'] / new_data['Avg_Death_0D']) * 100\n",
    "\n",
    "    reference_point = (control_data['Average Birth (1D)'].mean(), control_data['Average Death (1D)'].mean())\n",
    "\n",
    "    new_data['Distance %(1)'] = new_data.apply(\n",
    "        lambda row: np.sqrt((row['Average Birth (1D)'] - reference_point[0]) ** 2 + \n",
    "                    (row['Average Death (1D)'] - reference_point[1]) ** 2) * 100,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    new_data['Result(Cancer)'] = new_data.apply(\n",
    "        lambda row: 'Positive' if sum([\n",
    "            row['Regression Difference Percentage'] > k_1,\n",
    "            row['Distance %(1)'] > k_2,\n",
    "            row['1-Dim Hole Max Life Range'] > k_3,\n",
    "            row['1-Dim Hole Max Life Range'] < k_4\n",
    "        ]) >= 2 else 'Negative',\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    new_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Step 8: Count positive results per cohort\n",
    "    positive_counts = new_data[new_data['Result(Cancer)'] == 'Positive'].groupby('Cohort').size()\n",
    "\n",
    "    # Filter the results based on user-defined cancer types\n",
    "    results = {}\n",
    "    for tumor_type in tumor_types:\n",
    "        results[f\"{tumor_type} Positive\"] = positive_counts.get(tumor_type, 0)\n",
    "\n",
    "    # Calculate total positive cancers excluding 'Normal'\n",
    "    results[\"Total Positive Cancers\"] = sum(positive_counts.values) - positive_counts.get('Normal', 0)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "file_path = r'D:\\Cancer Detection folder\\Test\\Clinical cancer data.xlsx'\n",
    "sheet_name = 'Normal and Cancer'\n",
    "# User-defined variables\n",
    "biomarkers = ['Angiopoietin-2', 'CA-125', 'CA 15-3', 'CEA', 'CYFRA 21-1', 'FGF2', 'G-CSF', 'HE4', 'HGF', 'PAR', 'sPECAM-1', 'Thrombospondin-2']\n",
    "random_patient_range = 1802  # User-defined range\n",
    "control_data_range = 554  # User-defined control data range\n",
    "k_1 = 0.444  # User-defined regression threshold\n",
    "k_2 = 2.3  # User-defined distance threshold\n",
    "k_3 = 0.112  # User-defined upper threshold for 1D hole max life range\n",
    "k_4 = 0.047  # User-defined lower threshold for 1D hole max life range\n",
    "tumor_types = ['Normal', 'Breast', 'Colorectum', 'Esophagus', 'Liver', 'Lung', 'Ovary', 'Pancreas', 'Stomach']  # User-defined tumor types\n",
    "\n",
    "# Run the pipeline\n",
    "results = TDAcancer_detect_1(\n",
    "    file_path, biomarkers, random_patient_range, control_data_range, \n",
    "    k_1, k_2, k_3, k_4, tumor_types\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb466449-36f6-4b94-b5c2-7555f33e5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer Tissue Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5bf6ba-4871-4fd3-9db9-b51a6e46d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing combination 1: ['Angiopoietin-2', 'CA-125', 'CA 15-3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet1.csv\n",
      "Processing combination 2: ['Angiopoietin-2', 'CA-125', 'CEA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet2.csv\n",
      "Processing combination 3: ['Angiopoietin-2', 'CA-125', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet3.csv\n",
      "Processing combination 4: ['Angiopoietin-2', 'CA-125', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet4.csv\n",
      "Processing combination 5: ['Angiopoietin-2', 'CA-125', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet5.csv\n",
      "Processing combination 6: ['Angiopoietin-2', 'CA-125', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet6.csv\n",
      "Processing combination 7: ['Angiopoietin-2', 'CA-125', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet7.csv\n",
      "Processing combination 8: ['Angiopoietin-2', 'CA-125', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet8.csv\n",
      "Processing combination 9: ['Angiopoietin-2', 'CA-125', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet9.csv\n",
      "Processing combination 10: ['Angiopoietin-2', 'CA-125', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet10.csv\n",
      "Processing combination 11: ['Angiopoietin-2', 'CA 15-3', 'CEA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet11.csv\n",
      "Processing combination 12: ['Angiopoietin-2', 'CA 15-3', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet12.csv\n",
      "Processing combination 13: ['Angiopoietin-2', 'CA 15-3', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet13.csv\n",
      "Processing combination 14: ['Angiopoietin-2', 'CA 15-3', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet14.csv\n",
      "Processing combination 15: ['Angiopoietin-2', 'CA 15-3', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet15.csv\n",
      "Processing combination 16: ['Angiopoietin-2', 'CA 15-3', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet16.csv\n",
      "Processing combination 17: ['Angiopoietin-2', 'CA 15-3', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet17.csv\n",
      "Processing combination 18: ['Angiopoietin-2', 'CA 15-3', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet18.csv\n",
      "Processing combination 19: ['Angiopoietin-2', 'CA 15-3', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet19.csv\n",
      "Processing combination 20: ['Angiopoietin-2', 'CEA', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet20.csv\n",
      "Processing combination 21: ['Angiopoietin-2', 'CEA', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet21.csv\n",
      "Processing combination 22: ['Angiopoietin-2', 'CEA', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet22.csv\n",
      "Processing combination 23: ['Angiopoietin-2', 'CEA', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet23.csv\n",
      "Processing combination 24: ['Angiopoietin-2', 'CEA', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet24.csv\n",
      "Processing combination 25: ['Angiopoietin-2', 'CEA', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet25.csv\n",
      "Processing combination 26: ['Angiopoietin-2', 'CEA', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet26.csv\n",
      "Processing combination 27: ['Angiopoietin-2', 'CEA', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet27.csv\n",
      "Processing combination 28: ['Angiopoietin-2', 'CYFRA 21-1', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet28.csv\n",
      "Processing combination 29: ['Angiopoietin-2', 'CYFRA 21-1', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet29.csv\n",
      "Processing combination 30: ['Angiopoietin-2', 'CYFRA 21-1', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet30.csv\n",
      "Processing combination 31: ['Angiopoietin-2', 'CYFRA 21-1', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet31.csv\n",
      "Processing combination 32: ['Angiopoietin-2', 'CYFRA 21-1', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet32.csv\n",
      "Processing combination 33: ['Angiopoietin-2', 'CYFRA 21-1', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet33.csv\n",
      "Processing combination 34: ['Angiopoietin-2', 'CYFRA 21-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet34.csv\n",
      "Processing combination 35: ['Angiopoietin-2', 'FGF2', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet35.csv\n",
      "Processing combination 36: ['Angiopoietin-2', 'FGF2', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet36.csv\n",
      "Processing combination 37: ['Angiopoietin-2', 'FGF2', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet37.csv\n",
      "Processing combination 38: ['Angiopoietin-2', 'FGF2', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet38.csv\n",
      "Processing combination 39: ['Angiopoietin-2', 'FGF2', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet39.csv\n",
      "Processing combination 40: ['Angiopoietin-2', 'FGF2', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet40.csv\n",
      "Processing combination 41: ['Angiopoietin-2', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet41.csv\n",
      "Processing combination 42: ['Angiopoietin-2', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet42.csv\n",
      "Processing combination 43: ['Angiopoietin-2', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet43.csv\n",
      "Processing combination 44: ['Angiopoietin-2', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet44.csv\n",
      "Processing combination 45: ['Angiopoietin-2', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet45.csv\n",
      "Processing combination 46: ['Angiopoietin-2', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet46.csv\n",
      "Processing combination 47: ['Angiopoietin-2', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet47.csv\n",
      "Processing combination 48: ['Angiopoietin-2', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet48.csv\n",
      "Processing combination 49: ['Angiopoietin-2', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet49.csv\n",
      "Processing combination 50: ['Angiopoietin-2', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet50.csv\n",
      "Processing combination 51: ['Angiopoietin-2', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet51.csv\n",
      "Processing combination 52: ['Angiopoietin-2', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet52.csv\n",
      "Processing combination 53: ['Angiopoietin-2', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet53.csv\n",
      "Processing combination 54: ['Angiopoietin-2', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet54.csv\n",
      "Processing combination 55: ['Angiopoietin-2', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet55.csv\n",
      "Processing combination 56: ['CA-125', 'CA 15-3', 'CEA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet56.csv\n",
      "Processing combination 57: ['CA-125', 'CA 15-3', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet57.csv\n",
      "Processing combination 58: ['CA-125', 'CA 15-3', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet58.csv\n",
      "Processing combination 59: ['CA-125', 'CA 15-3', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet59.csv\n",
      "Processing combination 60: ['CA-125', 'CA 15-3', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet60.csv\n",
      "Processing combination 61: ['CA-125', 'CA 15-3', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet61.csv\n",
      "Processing combination 62: ['CA-125', 'CA 15-3', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet62.csv\n",
      "Processing combination 63: ['CA-125', 'CA 15-3', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet63.csv\n",
      "Processing combination 64: ['CA-125', 'CA 15-3', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet64.csv\n",
      "Processing combination 65: ['CA-125', 'CEA', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet65.csv\n",
      "Processing combination 66: ['CA-125', 'CEA', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet66.csv\n",
      "Processing combination 67: ['CA-125', 'CEA', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet67.csv\n",
      "Processing combination 68: ['CA-125', 'CEA', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet68.csv\n",
      "Processing combination 69: ['CA-125', 'CEA', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet69.csv\n",
      "Processing combination 70: ['CA-125', 'CEA', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet70.csv\n",
      "Processing combination 71: ['CA-125', 'CEA', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet71.csv\n",
      "Processing combination 72: ['CA-125', 'CEA', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet72.csv\n",
      "Processing combination 73: ['CA-125', 'CYFRA 21-1', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet73.csv\n",
      "Processing combination 74: ['CA-125', 'CYFRA 21-1', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet74.csv\n",
      "Processing combination 75: ['CA-125', 'CYFRA 21-1', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet75.csv\n",
      "Processing combination 76: ['CA-125', 'CYFRA 21-1', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet76.csv\n",
      "Processing combination 77: ['CA-125', 'CYFRA 21-1', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet77.csv\n",
      "Processing combination 78: ['CA-125', 'CYFRA 21-1', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet78.csv\n",
      "Processing combination 79: ['CA-125', 'CYFRA 21-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet79.csv\n",
      "Processing combination 80: ['CA-125', 'FGF2', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet80.csv\n",
      "Processing combination 81: ['CA-125', 'FGF2', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet81.csv\n",
      "Processing combination 82: ['CA-125', 'FGF2', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet82.csv\n",
      "Processing combination 83: ['CA-125', 'FGF2', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet83.csv\n",
      "Processing combination 84: ['CA-125', 'FGF2', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet84.csv\n",
      "Processing combination 85: ['CA-125', 'FGF2', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet85.csv\n",
      "Processing combination 86: ['CA-125', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet86.csv\n",
      "Processing combination 87: ['CA-125', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet87.csv\n",
      "Processing combination 88: ['CA-125', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet88.csv\n",
      "Processing combination 89: ['CA-125', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet89.csv\n",
      "Processing combination 90: ['CA-125', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet90.csv\n",
      "Processing combination 91: ['CA-125', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet91.csv\n",
      "Processing combination 92: ['CA-125', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet92.csv\n",
      "Processing combination 93: ['CA-125', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet93.csv\n",
      "Processing combination 94: ['CA-125', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet94.csv\n",
      "Processing combination 95: ['CA-125', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet95.csv\n",
      "Processing combination 96: ['CA-125', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet96.csv\n",
      "Processing combination 97: ['CA-125', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet97.csv\n",
      "Processing combination 98: ['CA-125', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet98.csv\n",
      "Processing combination 99: ['CA-125', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet99.csv\n",
      "Processing combination 100: ['CA-125', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet100.csv\n",
      "Processing combination 101: ['CA 15-3', 'CEA', 'CYFRA 21-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet101.csv\n",
      "Processing combination 102: ['CA 15-3', 'CEA', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet102.csv\n",
      "Processing combination 103: ['CA 15-3', 'CEA', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet103.csv\n",
      "Processing combination 104: ['CA 15-3', 'CEA', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet104.csv\n",
      "Processing combination 105: ['CA 15-3', 'CEA', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet105.csv\n",
      "Processing combination 106: ['CA 15-3', 'CEA', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet106.csv\n",
      "Processing combination 107: ['CA 15-3', 'CEA', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet107.csv\n",
      "Processing combination 108: ['CA 15-3', 'CEA', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet108.csv\n",
      "Processing combination 109: ['CA 15-3', 'CYFRA 21-1', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet109.csv\n",
      "Processing combination 110: ['CA 15-3', 'CYFRA 21-1', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet110.csv\n",
      "Processing combination 111: ['CA 15-3', 'CYFRA 21-1', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet111.csv\n",
      "Processing combination 112: ['CA 15-3', 'CYFRA 21-1', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet112.csv\n",
      "Processing combination 113: ['CA 15-3', 'CYFRA 21-1', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet113.csv\n",
      "Processing combination 114: ['CA 15-3', 'CYFRA 21-1', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet114.csv\n",
      "Processing combination 115: ['CA 15-3', 'CYFRA 21-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet115.csv\n",
      "Processing combination 116: ['CA 15-3', 'FGF2', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet116.csv\n",
      "Processing combination 117: ['CA 15-3', 'FGF2', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet117.csv\n",
      "Processing combination 118: ['CA 15-3', 'FGF2', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet118.csv\n",
      "Processing combination 119: ['CA 15-3', 'FGF2', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet119.csv\n",
      "Processing combination 120: ['CA 15-3', 'FGF2', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet120.csv\n",
      "Processing combination 121: ['CA 15-3', 'FGF2', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet121.csv\n",
      "Processing combination 122: ['CA 15-3', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet122.csv\n",
      "Processing combination 123: ['CA 15-3', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet123.csv\n",
      "Processing combination 124: ['CA 15-3', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet124.csv\n",
      "Processing combination 125: ['CA 15-3', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet125.csv\n",
      "Processing combination 126: ['CA 15-3', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet126.csv\n",
      "Processing combination 127: ['CA 15-3', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet127.csv\n",
      "Processing combination 128: ['CA 15-3', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet128.csv\n",
      "Processing combination 129: ['CA 15-3', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet129.csv\n",
      "Processing combination 130: ['CA 15-3', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet130.csv\n",
      "Processing combination 131: ['CA 15-3', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet131.csv\n",
      "Processing combination 132: ['CA 15-3', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet132.csv\n",
      "Processing combination 133: ['CA 15-3', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet133.csv\n",
      "Processing combination 134: ['CA 15-3', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet134.csv\n",
      "Processing combination 135: ['CA 15-3', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet135.csv\n",
      "Processing combination 136: ['CA 15-3', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet136.csv\n",
      "Processing combination 137: ['CEA', 'CYFRA 21-1', 'FGF2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet137.csv\n",
      "Processing combination 138: ['CEA', 'CYFRA 21-1', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet138.csv\n",
      "Processing combination 139: ['CEA', 'CYFRA 21-1', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet139.csv\n",
      "Processing combination 140: ['CEA', 'CYFRA 21-1', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet140.csv\n",
      "Processing combination 141: ['CEA', 'CYFRA 21-1', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet141.csv\n",
      "Processing combination 142: ['CEA', 'CYFRA 21-1', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet142.csv\n",
      "Processing combination 143: ['CEA', 'CYFRA 21-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet143.csv\n",
      "Processing combination 144: ['CEA', 'FGF2', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet144.csv\n",
      "Processing combination 145: ['CEA', 'FGF2', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet145.csv\n",
      "Processing combination 146: ['CEA', 'FGF2', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet146.csv\n",
      "Processing combination 147: ['CEA', 'FGF2', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet147.csv\n",
      "Processing combination 148: ['CEA', 'FGF2', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet148.csv\n",
      "Processing combination 149: ['CEA', 'FGF2', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet149.csv\n",
      "Processing combination 150: ['CEA', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet150.csv\n",
      "Processing combination 151: ['CEA', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet151.csv\n",
      "Processing combination 152: ['CEA', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet152.csv\n",
      "Processing combination 153: ['CEA', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet153.csv\n",
      "Processing combination 154: ['CEA', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet154.csv\n",
      "Processing combination 155: ['CEA', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet155.csv\n",
      "Processing combination 156: ['CEA', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet156.csv\n",
      "Processing combination 157: ['CEA', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet157.csv\n",
      "Processing combination 158: ['CEA', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet158.csv\n",
      "Processing combination 159: ['CEA', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet159.csv\n",
      "Processing combination 160: ['CEA', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet160.csv\n",
      "Processing combination 161: ['CEA', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet161.csv\n",
      "Processing combination 162: ['CEA', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet162.csv\n",
      "Processing combination 163: ['CEA', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet163.csv\n",
      "Processing combination 164: ['CEA', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet164.csv\n",
      "Processing combination 165: ['CYFRA 21-1', 'FGF2', 'G-CSF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet165.csv\n",
      "Processing combination 166: ['CYFRA 21-1', 'FGF2', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet166.csv\n",
      "Processing combination 167: ['CYFRA 21-1', 'FGF2', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet167.csv\n",
      "Processing combination 168: ['CYFRA 21-1', 'FGF2', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet168.csv\n",
      "Processing combination 169: ['CYFRA 21-1', 'FGF2', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet169.csv\n",
      "Processing combination 170: ['CYFRA 21-1', 'FGF2', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet170.csv\n",
      "Processing combination 171: ['CYFRA 21-1', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet171.csv\n",
      "Processing combination 172: ['CYFRA 21-1', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet172.csv\n",
      "Processing combination 173: ['CYFRA 21-1', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet173.csv\n",
      "Processing combination 174: ['CYFRA 21-1', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet174.csv\n",
      "Processing combination 175: ['CYFRA 21-1', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet175.csv\n",
      "Processing combination 176: ['CYFRA 21-1', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet176.csv\n",
      "Processing combination 177: ['CYFRA 21-1', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet177.csv\n",
      "Processing combination 178: ['CYFRA 21-1', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet178.csv\n",
      "Processing combination 179: ['CYFRA 21-1', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet179.csv\n",
      "Processing combination 180: ['CYFRA 21-1', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet180.csv\n",
      "Processing combination 181: ['CYFRA 21-1', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet181.csv\n",
      "Processing combination 182: ['CYFRA 21-1', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet182.csv\n",
      "Processing combination 183: ['CYFRA 21-1', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet183.csv\n",
      "Processing combination 184: ['CYFRA 21-1', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet184.csv\n",
      "Processing combination 185: ['CYFRA 21-1', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet185.csv\n",
      "Processing combination 186: ['FGF2', 'G-CSF', 'HE4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet186.csv\n",
      "Processing combination 187: ['FGF2', 'G-CSF', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet187.csv\n",
      "Processing combination 188: ['FGF2', 'G-CSF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet188.csv\n",
      "Processing combination 189: ['FGF2', 'G-CSF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet189.csv\n",
      "Processing combination 190: ['FGF2', 'G-CSF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet190.csv\n",
      "Processing combination 191: ['FGF2', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet191.csv\n",
      "Processing combination 192: ['FGF2', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet192.csv\n",
      "Processing combination 193: ['FGF2', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet193.csv\n",
      "Processing combination 194: ['FGF2', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet194.csv\n",
      "Processing combination 195: ['FGF2', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet195.csv\n",
      "Processing combination 196: ['FGF2', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet196.csv\n",
      "Processing combination 197: ['FGF2', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet197.csv\n",
      "Processing combination 198: ['FGF2', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet198.csv\n",
      "Processing combination 199: ['FGF2', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet199.csv\n",
      "Processing combination 200: ['FGF2', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet200.csv\n",
      "Processing combination 201: ['G-CSF', 'HE4', 'HGF']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet201.csv\n",
      "Processing combination 202: ['G-CSF', 'HE4', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet202.csv\n",
      "Processing combination 203: ['G-CSF', 'HE4', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet203.csv\n",
      "Processing combination 204: ['G-CSF', 'HE4', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet204.csv\n",
      "Processing combination 205: ['G-CSF', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet205.csv\n",
      "Processing combination 206: ['G-CSF', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet206.csv\n",
      "Processing combination 207: ['G-CSF', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet207.csv\n",
      "Processing combination 208: ['G-CSF', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet208.csv\n",
      "Processing combination 209: ['G-CSF', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet209.csv\n",
      "Processing combination 210: ['G-CSF', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet210.csv\n",
      "Processing combination 211: ['HE4', 'HGF', 'PAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet211.csv\n",
      "Processing combination 212: ['HE4', 'HGF', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet212.csv\n",
      "Processing combination 213: ['HE4', 'HGF', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet213.csv\n",
      "Processing combination 214: ['HE4', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet214.csv\n",
      "Processing combination 215: ['HE4', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet215.csv\n",
      "Processing combination 216: ['HE4', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet216.csv\n",
      "Processing combination 217: ['HGF', 'PAR', 'sPECAM-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet217.csv\n",
      "Processing combination 218: ['HGF', 'PAR', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet218.csv\n",
      "Processing combination 219: ['HGF', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet219.csv\n",
      "Processing combination 220: ['PAR', 'sPECAM-1', 'Thrombospondin-2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_combined, selected_biomarkers_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet220.csv\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet1.csv and D:\\Cancer Detection folder\\Test\\AverageDet1.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet2.csv and D:\\Cancer Detection folder\\Test\\AverageDet2.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet3.csv and D:\\Cancer Detection folder\\Test\\AverageDet3.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet4.csv and D:\\Cancer Detection folder\\Test\\AverageDet4.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet5.csv and D:\\Cancer Detection folder\\Test\\AverageDet5.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet6.csv and D:\\Cancer Detection folder\\Test\\AverageDet6.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet7.csv and D:\\Cancer Detection folder\\Test\\AverageDet7.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet8.csv and D:\\Cancer Detection folder\\Test\\AverageDet8.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet9.csv and D:\\Cancer Detection folder\\Test\\AverageDet9.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet10.csv and D:\\Cancer Detection folder\\Test\\AverageDet10.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet11.csv and D:\\Cancer Detection folder\\Test\\AverageDet11.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet12.csv and D:\\Cancer Detection folder\\Test\\AverageDet12.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet13.csv and D:\\Cancer Detection folder\\Test\\AverageDet13.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet14.csv and D:\\Cancer Detection folder\\Test\\AverageDet14.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet15.csv and D:\\Cancer Detection folder\\Test\\AverageDet15.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet16.csv and D:\\Cancer Detection folder\\Test\\AverageDet16.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet17.csv and D:\\Cancer Detection folder\\Test\\AverageDet17.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet18.csv and D:\\Cancer Detection folder\\Test\\AverageDet18.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet19.csv and D:\\Cancer Detection folder\\Test\\AverageDet19.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet20.csv and D:\\Cancer Detection folder\\Test\\AverageDet20.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet21.csv and D:\\Cancer Detection folder\\Test\\AverageDet21.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet22.csv and D:\\Cancer Detection folder\\Test\\AverageDet22.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet23.csv and D:\\Cancer Detection folder\\Test\\AverageDet23.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet24.csv and D:\\Cancer Detection folder\\Test\\AverageDet24.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet25.csv and D:\\Cancer Detection folder\\Test\\AverageDet25.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet26.csv and D:\\Cancer Detection folder\\Test\\AverageDet26.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet27.csv and D:\\Cancer Detection folder\\Test\\AverageDet27.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet28.csv and D:\\Cancer Detection folder\\Test\\AverageDet28.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet29.csv and D:\\Cancer Detection folder\\Test\\AverageDet29.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet30.csv and D:\\Cancer Detection folder\\Test\\AverageDet30.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet31.csv and D:\\Cancer Detection folder\\Test\\AverageDet31.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet32.csv and D:\\Cancer Detection folder\\Test\\AverageDet32.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet33.csv and D:\\Cancer Detection folder\\Test\\AverageDet33.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet34.csv and D:\\Cancer Detection folder\\Test\\AverageDet34.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet35.csv and D:\\Cancer Detection folder\\Test\\AverageDet35.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet36.csv and D:\\Cancer Detection folder\\Test\\AverageDet36.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet37.csv and D:\\Cancer Detection folder\\Test\\AverageDet37.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet38.csv and D:\\Cancer Detection folder\\Test\\AverageDet38.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet39.csv and D:\\Cancer Detection folder\\Test\\AverageDet39.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet40.csv and D:\\Cancer Detection folder\\Test\\AverageDet40.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet41.csv and D:\\Cancer Detection folder\\Test\\AverageDet41.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet42.csv and D:\\Cancer Detection folder\\Test\\AverageDet42.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet43.csv and D:\\Cancer Detection folder\\Test\\AverageDet43.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet44.csv and D:\\Cancer Detection folder\\Test\\AverageDet44.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet45.csv and D:\\Cancer Detection folder\\Test\\AverageDet45.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet46.csv and D:\\Cancer Detection folder\\Test\\AverageDet46.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet47.csv and D:\\Cancer Detection folder\\Test\\AverageDet47.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet48.csv and D:\\Cancer Detection folder\\Test\\AverageDet48.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet49.csv and D:\\Cancer Detection folder\\Test\\AverageDet49.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet50.csv and D:\\Cancer Detection folder\\Test\\AverageDet50.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet51.csv and D:\\Cancer Detection folder\\Test\\AverageDet51.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet52.csv and D:\\Cancer Detection folder\\Test\\AverageDet52.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet53.csv and D:\\Cancer Detection folder\\Test\\AverageDet53.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet54.csv and D:\\Cancer Detection folder\\Test\\AverageDet54.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet55.csv and D:\\Cancer Detection folder\\Test\\AverageDet55.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet56.csv and D:\\Cancer Detection folder\\Test\\AverageDet56.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet57.csv and D:\\Cancer Detection folder\\Test\\AverageDet57.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet58.csv and D:\\Cancer Detection folder\\Test\\AverageDet58.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet59.csv and D:\\Cancer Detection folder\\Test\\AverageDet59.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet60.csv and D:\\Cancer Detection folder\\Test\\AverageDet60.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet61.csv and D:\\Cancer Detection folder\\Test\\AverageDet61.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet62.csv and D:\\Cancer Detection folder\\Test\\AverageDet62.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet63.csv and D:\\Cancer Detection folder\\Test\\AverageDet63.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet64.csv and D:\\Cancer Detection folder\\Test\\AverageDet64.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet65.csv and D:\\Cancer Detection folder\\Test\\AverageDet65.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet66.csv and D:\\Cancer Detection folder\\Test\\AverageDet66.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet67.csv and D:\\Cancer Detection folder\\Test\\AverageDet67.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet68.csv and D:\\Cancer Detection folder\\Test\\AverageDet68.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet69.csv and D:\\Cancer Detection folder\\Test\\AverageDet69.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet70.csv and D:\\Cancer Detection folder\\Test\\AverageDet70.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet71.csv and D:\\Cancer Detection folder\\Test\\AverageDet71.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet72.csv and D:\\Cancer Detection folder\\Test\\AverageDet72.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet73.csv and D:\\Cancer Detection folder\\Test\\AverageDet73.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet74.csv and D:\\Cancer Detection folder\\Test\\AverageDet74.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet75.csv and D:\\Cancer Detection folder\\Test\\AverageDet75.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet76.csv and D:\\Cancer Detection folder\\Test\\AverageDet76.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet77.csv and D:\\Cancer Detection folder\\Test\\AverageDet77.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet78.csv and D:\\Cancer Detection folder\\Test\\AverageDet78.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet79.csv and D:\\Cancer Detection folder\\Test\\AverageDet79.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet80.csv and D:\\Cancer Detection folder\\Test\\AverageDet80.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet81.csv and D:\\Cancer Detection folder\\Test\\AverageDet81.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet82.csv and D:\\Cancer Detection folder\\Test\\AverageDet82.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet83.csv and D:\\Cancer Detection folder\\Test\\AverageDet83.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet84.csv and D:\\Cancer Detection folder\\Test\\AverageDet84.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet85.csv and D:\\Cancer Detection folder\\Test\\AverageDet85.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet86.csv and D:\\Cancer Detection folder\\Test\\AverageDet86.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet87.csv and D:\\Cancer Detection folder\\Test\\AverageDet87.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet88.csv and D:\\Cancer Detection folder\\Test\\AverageDet88.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet89.csv and D:\\Cancer Detection folder\\Test\\AverageDet89.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet90.csv and D:\\Cancer Detection folder\\Test\\AverageDet90.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet91.csv and D:\\Cancer Detection folder\\Test\\AverageDet91.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet92.csv and D:\\Cancer Detection folder\\Test\\AverageDet92.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet93.csv and D:\\Cancer Detection folder\\Test\\AverageDet93.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet94.csv and D:\\Cancer Detection folder\\Test\\AverageDet94.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet95.csv and D:\\Cancer Detection folder\\Test\\AverageDet95.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet96.csv and D:\\Cancer Detection folder\\Test\\AverageDet96.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet97.csv and D:\\Cancer Detection folder\\Test\\AverageDet97.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet98.csv and D:\\Cancer Detection folder\\Test\\AverageDet98.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet99.csv and D:\\Cancer Detection folder\\Test\\AverageDet99.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet100.csv and D:\\Cancer Detection folder\\Test\\AverageDet100.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet101.csv and D:\\Cancer Detection folder\\Test\\AverageDet101.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet102.csv and D:\\Cancer Detection folder\\Test\\AverageDet102.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet103.csv and D:\\Cancer Detection folder\\Test\\AverageDet103.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet104.csv and D:\\Cancer Detection folder\\Test\\AverageDet104.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet105.csv and D:\\Cancer Detection folder\\Test\\AverageDet105.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet106.csv and D:\\Cancer Detection folder\\Test\\AverageDet106.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet107.csv and D:\\Cancer Detection folder\\Test\\AverageDet107.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet108.csv and D:\\Cancer Detection folder\\Test\\AverageDet108.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet109.csv and D:\\Cancer Detection folder\\Test\\AverageDet109.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet110.csv and D:\\Cancer Detection folder\\Test\\AverageDet110.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet111.csv and D:\\Cancer Detection folder\\Test\\AverageDet111.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet112.csv and D:\\Cancer Detection folder\\Test\\AverageDet112.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet113.csv and D:\\Cancer Detection folder\\Test\\AverageDet113.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet114.csv and D:\\Cancer Detection folder\\Test\\AverageDet114.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet115.csv and D:\\Cancer Detection folder\\Test\\AverageDet115.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet116.csv and D:\\Cancer Detection folder\\Test\\AverageDet116.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet117.csv and D:\\Cancer Detection folder\\Test\\AverageDet117.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet118.csv and D:\\Cancer Detection folder\\Test\\AverageDet118.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet119.csv and D:\\Cancer Detection folder\\Test\\AverageDet119.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet120.csv and D:\\Cancer Detection folder\\Test\\AverageDet120.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet121.csv and D:\\Cancer Detection folder\\Test\\AverageDet121.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet122.csv and D:\\Cancer Detection folder\\Test\\AverageDet122.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet123.csv and D:\\Cancer Detection folder\\Test\\AverageDet123.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet124.csv and D:\\Cancer Detection folder\\Test\\AverageDet124.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet125.csv and D:\\Cancer Detection folder\\Test\\AverageDet125.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet126.csv and D:\\Cancer Detection folder\\Test\\AverageDet126.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet127.csv and D:\\Cancer Detection folder\\Test\\AverageDet127.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet128.csv and D:\\Cancer Detection folder\\Test\\AverageDet128.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet129.csv and D:\\Cancer Detection folder\\Test\\AverageDet129.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet130.csv and D:\\Cancer Detection folder\\Test\\AverageDet130.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet131.csv and D:\\Cancer Detection folder\\Test\\AverageDet131.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet132.csv and D:\\Cancer Detection folder\\Test\\AverageDet132.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet133.csv and D:\\Cancer Detection folder\\Test\\AverageDet133.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet134.csv and D:\\Cancer Detection folder\\Test\\AverageDet134.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet135.csv and D:\\Cancer Detection folder\\Test\\AverageDet135.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet136.csv and D:\\Cancer Detection folder\\Test\\AverageDet136.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet137.csv and D:\\Cancer Detection folder\\Test\\AverageDet137.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet138.csv and D:\\Cancer Detection folder\\Test\\AverageDet138.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet139.csv and D:\\Cancer Detection folder\\Test\\AverageDet139.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet140.csv and D:\\Cancer Detection folder\\Test\\AverageDet140.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet141.csv and D:\\Cancer Detection folder\\Test\\AverageDet141.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet142.csv and D:\\Cancer Detection folder\\Test\\AverageDet142.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet143.csv and D:\\Cancer Detection folder\\Test\\AverageDet143.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet144.csv and D:\\Cancer Detection folder\\Test\\AverageDet144.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet145.csv and D:\\Cancer Detection folder\\Test\\AverageDet145.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet146.csv and D:\\Cancer Detection folder\\Test\\AverageDet146.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet147.csv and D:\\Cancer Detection folder\\Test\\AverageDet147.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet148.csv and D:\\Cancer Detection folder\\Test\\AverageDet148.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet149.csv and D:\\Cancer Detection folder\\Test\\AverageDet149.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet150.csv and D:\\Cancer Detection folder\\Test\\AverageDet150.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet151.csv and D:\\Cancer Detection folder\\Test\\AverageDet151.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet152.csv and D:\\Cancer Detection folder\\Test\\AverageDet152.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet153.csv and D:\\Cancer Detection folder\\Test\\AverageDet153.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet154.csv and D:\\Cancer Detection folder\\Test\\AverageDet154.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet155.csv and D:\\Cancer Detection folder\\Test\\AverageDet155.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet156.csv and D:\\Cancer Detection folder\\Test\\AverageDet156.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet157.csv and D:\\Cancer Detection folder\\Test\\AverageDet157.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet158.csv and D:\\Cancer Detection folder\\Test\\AverageDet158.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet159.csv and D:\\Cancer Detection folder\\Test\\AverageDet159.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet160.csv and D:\\Cancer Detection folder\\Test\\AverageDet160.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet161.csv and D:\\Cancer Detection folder\\Test\\AverageDet161.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet162.csv and D:\\Cancer Detection folder\\Test\\AverageDet162.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet163.csv and D:\\Cancer Detection folder\\Test\\AverageDet163.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet164.csv and D:\\Cancer Detection folder\\Test\\AverageDet164.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet165.csv and D:\\Cancer Detection folder\\Test\\AverageDet165.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet166.csv and D:\\Cancer Detection folder\\Test\\AverageDet166.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet167.csv and D:\\Cancer Detection folder\\Test\\AverageDet167.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet168.csv and D:\\Cancer Detection folder\\Test\\AverageDet168.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet169.csv and D:\\Cancer Detection folder\\Test\\AverageDet169.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet170.csv and D:\\Cancer Detection folder\\Test\\AverageDet170.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet171.csv and D:\\Cancer Detection folder\\Test\\AverageDet171.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet172.csv and D:\\Cancer Detection folder\\Test\\AverageDet172.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet173.csv and D:\\Cancer Detection folder\\Test\\AverageDet173.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet174.csv and D:\\Cancer Detection folder\\Test\\AverageDet174.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet175.csv and D:\\Cancer Detection folder\\Test\\AverageDet175.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet176.csv and D:\\Cancer Detection folder\\Test\\AverageDet176.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet177.csv and D:\\Cancer Detection folder\\Test\\AverageDet177.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet178.csv and D:\\Cancer Detection folder\\Test\\AverageDet178.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet179.csv and D:\\Cancer Detection folder\\Test\\AverageDet179.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet180.csv and D:\\Cancer Detection folder\\Test\\AverageDet180.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet181.csv and D:\\Cancer Detection folder\\Test\\AverageDet181.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet182.csv and D:\\Cancer Detection folder\\Test\\AverageDet182.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet183.csv and D:\\Cancer Detection folder\\Test\\AverageDet183.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet184.csv and D:\\Cancer Detection folder\\Test\\AverageDet184.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet185.csv and D:\\Cancer Detection folder\\Test\\AverageDet185.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet186.csv and D:\\Cancer Detection folder\\Test\\AverageDet186.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet187.csv and D:\\Cancer Detection folder\\Test\\AverageDet187.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet188.csv and D:\\Cancer Detection folder\\Test\\AverageDet188.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet189.csv and D:\\Cancer Detection folder\\Test\\AverageDet189.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet190.csv and D:\\Cancer Detection folder\\Test\\AverageDet190.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet191.csv and D:\\Cancer Detection folder\\Test\\AverageDet191.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet192.csv and D:\\Cancer Detection folder\\Test\\AverageDet192.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet193.csv and D:\\Cancer Detection folder\\Test\\AverageDet193.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet194.csv and D:\\Cancer Detection folder\\Test\\AverageDet194.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet195.csv and D:\\Cancer Detection folder\\Test\\AverageDet195.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet196.csv and D:\\Cancer Detection folder\\Test\\AverageDet196.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet197.csv and D:\\Cancer Detection folder\\Test\\AverageDet197.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet198.csv and D:\\Cancer Detection folder\\Test\\AverageDet198.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet199.csv and D:\\Cancer Detection folder\\Test\\AverageDet199.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet200.csv and D:\\Cancer Detection folder\\Test\\AverageDet200.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet201.csv and D:\\Cancer Detection folder\\Test\\AverageDet201.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet202.csv and D:\\Cancer Detection folder\\Test\\AverageDet202.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet203.csv and D:\\Cancer Detection folder\\Test\\AverageDet203.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet204.csv and D:\\Cancer Detection folder\\Test\\AverageDet204.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet205.csv and D:\\Cancer Detection folder\\Test\\AverageDet205.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet206.csv and D:\\Cancer Detection folder\\Test\\AverageDet206.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet207.csv and D:\\Cancer Detection folder\\Test\\AverageDet207.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet208.csv and D:\\Cancer Detection folder\\Test\\AverageDet208.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet209.csv and D:\\Cancer Detection folder\\Test\\AverageDet209.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet210.csv and D:\\Cancer Detection folder\\Test\\AverageDet210.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet211.csv and D:\\Cancer Detection folder\\Test\\AverageDet211.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet212.csv and D:\\Cancer Detection folder\\Test\\AverageDet212.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet213.csv and D:\\Cancer Detection folder\\Test\\AverageDet213.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet214.csv and D:\\Cancer Detection folder\\Test\\AverageDet214.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet215.csv and D:\\Cancer Detection folder\\Test\\AverageDet215.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet216.csv and D:\\Cancer Detection folder\\Test\\AverageDet216.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet217.csv and D:\\Cancer Detection folder\\Test\\AverageDet217.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet218.csv and D:\\Cancer Detection folder\\Test\\AverageDet218.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet219.csv and D:\\Cancer Detection folder\\Test\\AverageDet219.csv successfully.\n",
      "Processed and updated D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet220.csv and D:\\Cancer Detection folder\\Test\\AverageDet220.csv successfully.\n",
      "Merged file saved as: D:\\Cancer Detection folder\\Test\\Average1.xlsx\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet1.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet1.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet2.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet2.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet3.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet3.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet4.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet4.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet5.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet5.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet6.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet6.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet7.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet7.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet8.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet8.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet9.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet9.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet10.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet10.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet11.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet11.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet12.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet12.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet13.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet13.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet14.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet14.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet15.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet15.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet16.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet16.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet17.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet17.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet18.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet18.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet19.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet19.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet20.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet20.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet21.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet21.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet22.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet22.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet23.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet23.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet24.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet24.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet25.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet25.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet26.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet26.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet27.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet27.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet28.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet28.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet29.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet29.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet30.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet30.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet31.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet31.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet32.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet32.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet33.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet33.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet34.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet34.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet35.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet35.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet36.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet36.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet37.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet37.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet38.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet38.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet39.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet39.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet40.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet40.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet41.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet41.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet42.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet42.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet43.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet43.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet44.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet44.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet45.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet45.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet46.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet46.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet47.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet47.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet48.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet48.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet49.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet49.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet50.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet50.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet51.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet51.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet52.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet52.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet53.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet53.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet54.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet54.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet55.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet55.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet56.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet56.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet57.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet57.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet58.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet58.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet59.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet59.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet60.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet60.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet61.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet61.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet62.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet62.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet63.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet63.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet64.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet64.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet65.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet65.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet66.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet66.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet67.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet67.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet68.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet68.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet69.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet69.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet70.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet70.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet71.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet71.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet72.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet72.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet73.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet73.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet74.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet74.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet75.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet75.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet76.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet76.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet77.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet77.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet78.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet78.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet79.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet79.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet80.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet80.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet81.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet81.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet82.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet82.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet83.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet83.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet84.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet84.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet85.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet85.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet86.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet86.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet87.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet87.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet88.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet88.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet89.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet89.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet90.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet90.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet91.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet91.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet92.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet92.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet93.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet93.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet94.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet94.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet95.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet95.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet96.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet96.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet97.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet97.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet98.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet98.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet99.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet99.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet100.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet100.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet101.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet101.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet102.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet102.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet103.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet103.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet104.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet104.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet105.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet105.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet106.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet106.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet107.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet107.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet108.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet108.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet109.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet109.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet110.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet110.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet111.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet111.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet112.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet112.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet113.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet113.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet114.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet114.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet115.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet115.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet116.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet116.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet117.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet117.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet118.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet118.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet119.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet119.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet120.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet120.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet121.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet121.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet122.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet122.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet123.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet123.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet124.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet124.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet125.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet125.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet126.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet126.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet127.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet127.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet128.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet128.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet129.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet129.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet130.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet130.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet131.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet131.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet132.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet132.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet133.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet133.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet134.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet134.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet135.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet135.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet136.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet136.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet137.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet137.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet138.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet138.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet139.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet139.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet140.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet140.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet141.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet141.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet142.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet142.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet143.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet143.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet144.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet144.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet145.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet145.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet146.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet146.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet147.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet147.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet148.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet148.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet149.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet149.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet150.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet150.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet151.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet151.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet152.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet152.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet153.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet153.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet154.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet154.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet155.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet155.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet156.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet156.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet157.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet157.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet158.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet158.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet159.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet159.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet160.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet160.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet161.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet161.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet162.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet162.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet163.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet163.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet164.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet164.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet165.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet165.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet166.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet166.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet167.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet167.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet168.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet168.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet169.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet169.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet170.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet170.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet171.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet171.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet172.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet172.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet173.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet173.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet174.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet174.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet175.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet175.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet176.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet176.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet177.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet177.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet178.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet178.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet179.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet179.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet180.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet180.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet181.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet181.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet182.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet182.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet183.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet183.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet184.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet184.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet185.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet185.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet186.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet186.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet187.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet187.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet188.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet188.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet189.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet189.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet190.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet190.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet191.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet191.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet192.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet192.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet193.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet193.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet194.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet194.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet195.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet195.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet196.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet196.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet197.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet197.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet198.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet198.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet199.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet199.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet200.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet200.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet201.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet201.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet202.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet202.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet203.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet203.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet204.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet204.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet205.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet205.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet206.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet206.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet207.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet207.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet208.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet208.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet209.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet209.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet210.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet210.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet211.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet211.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet212.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet212.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet213.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet213.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet214.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet214.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet215.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet215.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet216.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet216.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet217.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet217.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet218.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet218.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet219.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet219.csv\n",
      "Processed: D:\\Cancer Detection folder\\Test\\FeatureVectorTissueDet220.csv → Saved: D:\\Cancer Detection folder\\Test\\Positives\\positives_countDet220.csv\n",
      "Merged file saved as: D:\\Cancer Detection folder\\Test\\Positives\\Positives1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:415: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
      "C:\\Users\\Sudarshan Gogoi\\AppData\\Local\\Temp\\ipykernel_21384\\934484306.py:416: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: D:\\Cancer Detection folder\\Test\\Positives\\Positives1.xlsx\n",
      "Processing Cohort: Breast\n",
      "Processing Cohort: Colorectum\n",
      "Processing Cohort: Esophagus\n",
      "Processing Cohort: Liver\n",
      "Processing Cohort: Lung\n",
      "Processing Cohort: Ovary\n",
      "Processing Cohort: Pancreas\n",
      "Processing Cohort: Stomach\n",
      "Results saved to D:\\Cancer Detection folder\\Test\\Positives\\Top_5_Sensitivities.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gudhi\n",
    "from itertools import combinations\n",
    "\n",
    "def TDAcancer_detect_2(file_path, sheet_name, biomarkers, output_dir, tumor_types, total_positive_patients, num_combinations, random_patient_range, cohorts_to_analyze):\n",
    "    \n",
    "    # ==================================================\n",
    "    # Part 1: Preliminary Analysis and Formation of Average1.xlsx\n",
    "    # ==================================================\n",
    "\n",
    "    def calculate_averages(output_dir, tumor_types, total_positive_patients, num_combinations):\n",
    "        # File paths\n",
    "        cancer_result_file = os.path.join(output_dir, 'Clinical cancer data_features.csv')\n",
    "        base_feature_vector_path = os.path.join(output_dir, 'FeatureVectorTissueDet{}.csv')\n",
    "        base_average_path = os.path.join(output_dir, 'AverageDet{}.csv')\n",
    "\n",
    "        # Load the cancer results file\n",
    "        cancer_data = pd.read_csv(cancer_result_file)\n",
    "\n",
    "        # Columns for averaging\n",
    "        columns_to_average = ['0-Dim Hole Min Life Range', 'Range_Death_0D']\n",
    "\n",
    "        # Process files from FeatureVectorTissueDet1.csv to FeatureVectorTissueDetN.csv\n",
    "        for i in range(1, num_combinations + 1):\n",
    "            file_path = base_feature_vector_path.format(i)\n",
    "            try:\n",
    "                new_data = pd.read_csv(file_path)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {file_path} not found, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Add 'Result(Cancer)' column\n",
    "            new_data['Result(Cancer)'] = cancer_data['Result(Cancer)']\n",
    "            new_data.to_csv(file_path, index=False)\n",
    "            \n",
    "            # Compute cohort averages\n",
    "            averages_list = []\n",
    "            for tumor, row_limit in tumor_types.items():\n",
    "                if tumor == 'normal':\n",
    "                    filtered_data = new_data[(new_data['Cohort'].str.strip().str.lower() == tumor) & (new_data['Result(Cancer)'] == 'Negative')]\n",
    "                else:\n",
    "                    filtered_data = new_data[(new_data['Cohort'].str.strip().str.lower() == tumor) & (new_data['Result(Cancer)'] == 'Positive')]\n",
    "                \n",
    "                selected_data = filtered_data.iloc[:row_limit][columns_to_average].dropna()\n",
    "                averages_list.append({'Cohort': tumor.capitalize(), **selected_data.mean().to_dict()})\n",
    "            \n",
    "            averages_data = pd.DataFrame(averages_list)\n",
    "            normal_averages = averages_data[averages_data['Cohort'].str.lower() == 'normal']\n",
    "            reference_point = (\n",
    "                float(normal_averages['0-Dim Hole Min Life Range'].values[0]),\n",
    "                float(normal_averages['Range_Death_0D'].values[0])\n",
    "            )\n",
    "            \n",
    "            # Compute Euclidean distance\n",
    "            X = new_data[['0-Dim Hole Min Life Range']].values\n",
    "            y = new_data['Range_Death_0D'].values\n",
    "            distances = [np.sqrt((X[i][0] - reference_point[0]) ** 2 + (y[i] - reference_point[1]) ** 2) for i in range(len(X))]\n",
    "            new_data['Distance %(3)'] = [d * 100 for d in distances]\n",
    "            new_data.to_csv(file_path, index=False)\n",
    "            \n",
    "            # Compute distance averages\n",
    "            averages_distance = []\n",
    "            for tumor, row_limit in tumor_types.items():\n",
    "                if tumor == 'normal':\n",
    "                    filtered_data = new_data[(new_data['Cohort'].str.strip().str.lower() == tumor) & (new_data['Result(Cancer)'] == 'Negative')]\n",
    "                else:\n",
    "                    filtered_data = new_data[(new_data['Cohort'].str.strip().str.lower() == tumor) & (new_data['Result(Cancer)'] == 'Positive')]\n",
    "                \n",
    "                selected_data = filtered_data.iloc[:row_limit][columns_to_average + ['Distance %(3)']].dropna()\n",
    "                averages_distance.append({'Cohort': tumor.capitalize(), 'Average Distance %(3)': selected_data['Distance %(3)'].mean(), **selected_data.mean().to_dict()})\n",
    "            \n",
    "            averages_distance_data = pd.DataFrame(averages_distance)\n",
    "            averages_distance_data.to_csv(base_average_path.format(i), index=False)\n",
    "            \n",
    "            # Determine threshold\n",
    "            sorted_distances = averages_distance_data['Average Distance %(3)'].sort_values(ascending=False)\n",
    "            second_highest_distance = sorted_distances.iloc[1]\n",
    "            k = int(np.ceil(second_highest_distance))\n",
    "            \n",
    "            # Localize cancer tissue\n",
    "            new_data['Result(Tissue Detection)'] = ['Positive' if value > k else 'Negative' for value in new_data['Distance %(3)']]\n",
    "            new_data['Cancer tissue'] = new_data.apply(lambda row: 'Positive' if row['Result(Cancer)'] == 'Positive' and row['Result(Tissue Detection)'] == 'Positive' else 'Negative', axis=1)\n",
    "            new_data.to_csv(file_path, index=False)\n",
    "            \n",
    "            print(f\"Processed and updated {file_path} and {base_average_path.format(i)} successfully.\")\n",
    "\n",
    "    def merge_averages_to_excel(output_dir, num_combinations):\n",
    "        # Function for natural sorting (e.g., 1,2,3 instead of 1,10,100)\n",
    "        def natural_sort_key(text):\n",
    "            return [int(num) if num.isdigit() else num for num in re.split(r'(\\d+)', text)]\n",
    "\n",
    "        # Merge AverageDet CSV files into Average1.xlsx\n",
    "        # Get a sorted list of all relevant CSV files\n",
    "        csv_files = sorted(\n",
    "            [f for f in os.listdir(output_dir) if f.startswith(\"AverageDet\") and f.endswith(\".csv\")],\n",
    "            key=natural_sort_key\n",
    "        )\n",
    "\n",
    "        # Initialize an empty DataFrame for merging\n",
    "        merged_df = None\n",
    "\n",
    "        # Loop through each file and process\n",
    "        for i, file in enumerate(csv_files, start=1):\n",
    "            if i > num_combinations:\n",
    "                break  # Stop after processing the specified number of combinations\n",
    "            \n",
    "            # Read the current CSV file\n",
    "            file_path = os.path.join(output_dir, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Select only the \"Cohort\" and \"Average Distance %(3)\" columns\n",
    "            df = df[[\"Cohort\", \"Average Distance %(3)\"]]\n",
    "\n",
    "            # Rename the \"Average Distance %(3)\" column to include the file index\n",
    "            df.rename(columns={\"Average Distance %(3)\": f\"Average Distance %(3)-{i}\"}, inplace=True)\n",
    "\n",
    "            # Merge with accumulated DataFrame\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on=\"Cohort\", how=\"outer\")\n",
    "\n",
    "        # Save the merged DataFrame to an Excel file\n",
    "        output_file_path = os.path.join(output_dir, \"Average1.xlsx\")\n",
    "        merged_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "        print(f\"Merged file saved as: {output_file_path}\")\n",
    "\n",
    "    def process_clinical_data(file_path, sheet_name, biomarkers, output_dir, tumor_types, total_positive_patients, num_combinations, random_patient_range):\n",
    "        # Step 1: Load the clinical data\n",
    "        df_1 = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df_2 = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "        # Generate all combinations of 3 biomarkers\n",
    "        biomarker_combinations = list(combinations(biomarkers, 3))\n",
    "        if num_combinations > len(biomarker_combinations):\n",
    "            print(f\"Warning: Only {len(biomarker_combinations)} combinations available. Processing {len(biomarker_combinations)} combinations instead of {num_combinations}.\")\n",
    "            num_combinations = len(biomarker_combinations)\n",
    "\n",
    "        # Directory to save the CSV files\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Step 2: Iterate through each combination of biomarkers\n",
    "        for combo_index, combo in enumerate(biomarker_combinations[:num_combinations], start=1):\n",
    "            # Select biomarkers for this iteration\n",
    "            columns_to_select = list(combo)\n",
    "            print(f\"Processing combination {combo_index}: {columns_to_select}\")\n",
    "\n",
    "            # Subset the data\n",
    "            df_1_subset = df_1[columns_to_select].iloc[:59]  # First 59 rows for normal patients\n",
    "            df_2_subset = df_2[columns_to_select]           # All rows for cancer patients\n",
    "\n",
    "            # Initialize a list to store feature vectors\n",
    "            data_list = []\n",
    "\n",
    "            # Step 4: Add additional random patient data for analysis\n",
    "            for index in range(60, random_patient_range + 1):  # User-defined range\n",
    "                # Select a specific row from df_2\n",
    "                row_to_add = df_2_subset.iloc[[index]]\n",
    "\n",
    "                # Combine it with the fixed dataset\n",
    "                df_combined = pd.concat([df_1_subset] + [row_to_add] * 1, ignore_index=True)\n",
    "\n",
    "                # Step 5: Log normalize the combined data\n",
    "                numeric_cols = df_combined.select_dtypes(include=[np.number]).columns\n",
    "                df_combined[numeric_cols] = np.log(df_combined[numeric_cols])\n",
    "\n",
    "                # Convert DataFrame to numpy array\n",
    "                df_subset = df_combined.values\n",
    "\n",
    "                # Step 6: Calculate Pearson correlation matrix and distance matrix\n",
    "                corr_matrix = np.corrcoef(df_subset, rowvar=False)\n",
    "                corr_matrix_df = pd.DataFrame(corr_matrix, columns=columns_to_select, index=columns_to_select)\n",
    "                distance_matrix = 1 - np.abs(corr_matrix_df)\n",
    "                distance_matrix_np = distance_matrix.values\n",
    "\n",
    "                # Step 7: Construct a simplicial complex using Gudhi's RipsComplex\n",
    "                rips_complex = gudhi.RipsComplex(distance_matrix=distance_matrix_np)\n",
    "                simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "                persistence = simplex_tree.persistence()\n",
    "\n",
    "                # Step 8: Extract topological features\n",
    "                finite_persistence = [(dim, (birth, death)) for dim, (birth, death) in persistence if death != float('inf')]\n",
    "                one_dim_holes = [(birth, death) for dim, (birth, death) in finite_persistence if dim == 1]\n",
    "                \n",
    "                if one_dim_holes:\n",
    "                    max_life_range_1D = max(death - birth for birth, death in one_dim_holes)\n",
    "                    avg_birth_1D = np.mean([birth for birth, _ in one_dim_holes])\n",
    "                    avg_death_1D = np.mean([death for _, death in one_dim_holes])\n",
    "                    num_one_dim_holes = len(one_dim_holes)\n",
    "                else:\n",
    "                    max_life_range_1D = avg_birth_1D = avg_death_1D = num_one_dim_holes = 0\n",
    "\n",
    "                zero_dim_holes = [(birth, death) for dim, (birth, death) in finite_persistence if dim == 0]\n",
    "                min_life_range_0D = min(death - birth for birth, death in zero_dim_holes)\n",
    "                max_life_range_0D = max(death - birth for birth, death in zero_dim_holes)\n",
    "                avg_death_0D = np.mean([death for _, death in zero_dim_holes])\n",
    "                num_zero_dim_holes = len(zero_dim_holes) + 1\n",
    "                range_death_0D = max([death for _, death in zero_dim_holes]) - min([death for _, death in zero_dim_holes])\n",
    "                median_death_0D = np.median([death for _, death in zero_dim_holes])\n",
    "                std_death_0D = np.std([death for _, death in zero_dim_holes])\n",
    "\n",
    "                # Prepare feature vector\n",
    "                data = {\n",
    "                    \"0-Dim Hole Min Life Range\": [min_life_range_0D],\n",
    "                    \"0-Dim Hole Max Life Range\": [max_life_range_0D],\n",
    "                    \"Range_Death_0D\": [range_death_0D],\n",
    "                    \"Num_0D_Holes\": [num_zero_dim_holes],\n",
    "                    \"Median_Death_0D\": [median_death_0D],\n",
    "                    \"Std_Death_0D\": [std_death_0D],\n",
    "                    \"Avg_Death_0D\": [avg_death_0D],\n",
    "                    \"Average Birth (1D)\": [avg_birth_1D],\n",
    "                    \"Average Death (1D)\": [avg_death_1D],\n",
    "                    \"1-Dim Hole Max Life Range\": [max_life_range_1D],\n",
    "                    \"Number of 1-Dimensional Holes\": [num_one_dim_holes]\n",
    "                }\n",
    "\n",
    "                # Append to list\n",
    "                df_features = pd.DataFrame(data, index=[f\"P_{index}\"])\n",
    "                data_list.append(df_features)\n",
    "\n",
    "            # Concatenate all feature vectors for the current combination\n",
    "            final_df = pd.concat(data_list)\n",
    "\n",
    "            # Add additional clinical information\n",
    "            additional_columns = ['Patient ID #', 'Cohort', 'AJCC Stage']\n",
    "            df_clinical = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "            df_additional_info = df_clinical[additional_columns].iloc[60:random_patient_range + 1]\n",
    "            additional_info_index = [f\"P_{i}\" for i in range(60, random_patient_range + 1)]\n",
    "            df_additional_info.index = additional_info_index\n",
    "\n",
    "            # Merge with topological data\n",
    "            df_combined = pd.concat([df_additional_info, final_df], axis=1)\n",
    "\n",
    "            # Append biomarkers as the last row\n",
    "            selected_biomarkers_row = pd.DataFrame(\n",
    "                {col: None for col in df_combined.columns}, \n",
    "                index=[\"Selected Biomarkers\"]\n",
    "            )\n",
    "            selected_biomarkers_row.iloc[0, :len(columns_to_select)] = columns_to_select\n",
    "            df_combined = pd.concat([df_combined, selected_biomarkers_row])\n",
    "\n",
    "            # Save to a CSV file\n",
    "            csv_file_path = os.path.join(output_dir, f\"FeatureVectorTissueDet{combo_index}.csv\")\n",
    "            df_combined.to_csv(csv_file_path, float_format=\"%f\", index=True)\n",
    "            print(f\"Saved: {csv_file_path}\")\n",
    "\n",
    "        # Step 9: Calculate averages and generate Average1.xlsx\n",
    "        calculate_averages(output_dir, tumor_types, total_positive_patients, num_combinations)\n",
    "        merge_averages_to_excel(output_dir, num_combinations)\n",
    "\n",
    "    # ==================================================\n",
    "    # Part 2: Formation of Positives1.xlsx and Sensitivity Outcomes\n",
    "    # ==================================================\n",
    "\n",
    "    def merge_positives_to_excel(output_dir, tumor_types, num_combinations):\n",
    "        # Directory paths\n",
    "        input_dir = output_dir\n",
    "        positives_dir = os.path.join(input_dir, 'Positives')\n",
    "\n",
    "        # Ensure the output directory exists\n",
    "        os.makedirs(positives_dir, exist_ok=True)\n",
    "\n",
    "        # Loop through files 1 to N\n",
    "        for i in range(1, num_combinations + 1):\n",
    "            input_file_path = os.path.join(input_dir, f'FeatureVectorTissueDet{i}.csv')\n",
    "            output_file_path = os.path.join(positives_dir, f'positives_countDet{i}.csv')\n",
    "\n",
    "            try:\n",
    "                # Step 1: Load the CSV file\n",
    "                new_data = pd.read_csv(input_file_path, header=0)\n",
    "\n",
    "                # Step 2: Initialize an empty list to store results\n",
    "                results = []\n",
    "\n",
    "                # Step 3: Count the number of positives for each Cohort and each AJCC Stage\n",
    "                for tumor_type in tumor_types:\n",
    "                    # Filter data for the current Cohort\n",
    "                    tumor_data = new_data[new_data['Cohort'] == tumor_type]\n",
    "\n",
    "                    # Count positives for each AJCC stage (I, II, III)\n",
    "                    for stage in ['I', 'II', 'III']:\n",
    "                        stage_data = tumor_data[tumor_data['AJCC Stage'] == stage]\n",
    "\n",
    "                        # Count positives for 'Cancer tissue' column\n",
    "                        positive_count = stage_data[stage_data['Cancer tissue'] == 'Positive'].shape[0]\n",
    "\n",
    "                        # Append result to the list\n",
    "                        results.append({'Cohort': tumor_type, 'AJCC Stage': stage, 'Positive Count': positive_count})\n",
    "\n",
    "                    # Count positives for all AJCC stages combined\n",
    "                    total_positive_count = tumor_data[tumor_data['Cancer tissue'] == 'Positive'].shape[0]\n",
    "                    results.append({'Cohort': tumor_type, 'AJCC Stage': 'All Stages', 'Positive Count': total_positive_count})\n",
    "\n",
    "                # Step 4: Convert the results into a DataFrame and save to CSV\n",
    "                results_df = pd.DataFrame(results)\n",
    "                results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "                print(f\"Processed: {input_file_path} → Saved: {output_file_path}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {input_file_path}, skipping...\")\n",
    "\n",
    "        # Merge all positives_countDet CSV files into Positives1.xlsx\n",
    "        # Function for natural sorting (e.g., 1,2,3 instead of 1,10,100)\n",
    "        def natural_sort_key(text):\n",
    "            return [int(num) if num.isdigit() else num for num in re.split(r'(\\d+)', text)]\n",
    "\n",
    "        # Get a sorted list of all relevant CSV files\n",
    "        csv_files = sorted(\n",
    "            [f for f in os.listdir(positives_dir) if f.startswith(\"positives_countDet\") and f.endswith(\".csv\")],\n",
    "            key=natural_sort_key\n",
    "        )\n",
    "\n",
    "        # Initialize an empty list to store DataFrames\n",
    "        dfs = []\n",
    "\n",
    "        # Loop through each file and process it\n",
    "        for i, file in enumerate(csv_files, start=1):\n",
    "            if i > num_combinations:\n",
    "                break  # Stop after processing the specified number of combinations\n",
    "            \n",
    "            # Read the current CSV file\n",
    "            file_path = os.path.join(positives_dir, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Filter rows based on conditions\n",
    "            df = df[(df[\"AJCC Stage\"] == \"All Stages\") & (df[\"Cohort\"].isin(tumor_types))]\n",
    "\n",
    "            # Rename the \"Positive Count\" column to include the file index\n",
    "            df.rename(columns={\"Positive Count\": f\"Positive Det {i}\"}, inplace=True)\n",
    "\n",
    "            # Append the processed DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "        # Merge all DataFrames on \"Cohort\" and \"AJCC Stage\"\n",
    "        merged_df = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            merged_df = pd.merge(merged_df, df, on=[\"Cohort\", \"AJCC Stage\"], how=\"outer\")\n",
    "\n",
    "        # Sort the final DataFrame by \"Cohort\" and \"AJCC Stage\" for consistency\n",
    "        merged_df = merged_df.sort_values(by=[\"Cohort\", \"AJCC Stage\"]).reset_index(drop=True)\n",
    "\n",
    "        # Add \"Total Positive Patients\" column\n",
    "        merged_df[\"Total Positive Patients\"] = merged_df[\"Cohort\"].map(total_positive_patients)\n",
    "\n",
    "        # Reorder columns to place \"Total Positive Patients\" after \"AJCC Stage\"\n",
    "        cols = [\"Cohort\", \"AJCC Stage\", \"Total Positive Patients\"] + [col for col in merged_df.columns if col.startswith(\"Positive Det\")]\n",
    "        merged_df = merged_df[cols]\n",
    "\n",
    "        # Save the merged DataFrame to an Excel file\n",
    "        output_file_path = os.path.join(positives_dir, \"Positives1.xlsx\")\n",
    "        merged_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "        print(f\"Merged file saved as: {output_file_path}\")\n",
    "\n",
    "    def calculate_sensitivity_and_accuracy(output_dir, tumor_types, total_positive_patients, num_combinations):\n",
    "        # Load data from Excel files\n",
    "        positives_file_path = os.path.join(output_dir, 'Positives', 'Positives1.xlsx')\n",
    "        averages_file_path = os.path.join(output_dir, 'Average1.xlsx')\n",
    "\n",
    "        positives_df = pd.read_excel(positives_file_path)\n",
    "        averages_df = pd.read_excel(averages_file_path)\n",
    "\n",
    "        # Get the list of Positive Count columns\n",
    "        positive_count_columns = [col for col in positives_df.columns if col.startswith(\"Positive Det\")]\n",
    "\n",
    "        # Initialize columns for results\n",
    "        results = {\"Sensitivity\": [], \"Accuracy\": [], \"Cohort\": []}\n",
    "\n",
    "        # Total number of positive patients across all Cohorts\n",
    "        total_patients = positives_df[\"Total Positive Patients\"].sum()\n",
    "\n",
    "        # Loop through each Positive Count column\n",
    "        for i, column in enumerate(positive_count_columns, start=1):\n",
    "            if i > num_combinations:\n",
    "                break  # Stop after processing the specified number of combinations\n",
    "            \n",
    "            # Determine the Cohort type based on the highest value in the corresponding \"Average Distance %(3)-i\" column\n",
    "            avg_column = f\"Average Distance %(3)-{i}\"\n",
    "            \n",
    "            if avg_column not in averages_df.columns:\n",
    "                print(f\"Column {avg_column} not found in Averages file, skipping...\")\n",
    "                continue  # Skip this iteration if column is missing\n",
    "            \n",
    "            max_value_row = averages_df[avg_column].idxmax()\n",
    "            Cohort_type = averages_df.loc[max_value_row, \"Cohort\"]\n",
    "\n",
    "            # Ensure the Cohort exists in positives_df\n",
    "            Cohort_row = positives_df[positives_df[\"Cohort\"] == Cohort_type]\n",
    "            if Cohort_row.empty:\n",
    "                print(f\"Cohort {Cohort_type} not found in Positives file, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            Cohort_row = Cohort_row.iloc[0]  # Convert to Series\n",
    "            \n",
    "            # Extract necessary values\n",
    "            TP = Cohort_row[column]  # True Positives\n",
    "            FN = Cohort_row[\"Total Positive Patients\"] - TP  # False Negatives\n",
    "            FP = positives_df[column].sum() - TP  # False Positives\n",
    "            TN = total_patients - (TP + FP + FN)  # True Negatives\n",
    "\n",
    "            # Calculate Sensitivity and Accuracy\n",
    "            sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "            accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "            \n",
    "            # Append results\n",
    "            results[\"Sensitivity\"].append(sensitivity)\n",
    "            results[\"Accuracy\"].append(accuracy)\n",
    "            results[\"Cohort\"].append(Cohort_type)\n",
    "\n",
    "            # Write results into the DataFrame\n",
    "            positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Sensitivity {i}\"] = sensitivity\n",
    "            positives_df.loc[positives_df[\"Cohort\"] == Cohort_type, f\"Accuracy {i}\"] = accuracy\n",
    "\n",
    "        # Save the results back to the Excel file\n",
    "        positives_df.to_excel(positives_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "        print(f\"Results saved to: {positives_file_path}\")\n",
    "\n",
    "    def get_top_5_sensitivities(output_dir, tumor_types, num_combinations):\n",
    "        excel_file_path = os.path.join(output_dir, 'Positives', 'Positives1.xlsx')\n",
    "        csv_file_folder = output_dir\n",
    "        output_path = os.path.join(output_dir, 'Positives')\n",
    "\n",
    "        # Read the Excel file\n",
    "        excel_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "        # Function for natural sorting (e.g., 1,2,3 instead of 1,10,100)\n",
    "        def natural_sort_key(text):\n",
    "            return [int(num) if num.isdigit() else num for num in re.split(r'(\\d+)', text)]\n",
    "\n",
    "        # Function to get selected biomarkers from the appropriate CSV file\n",
    "        def get_selected_biomarkers(csv_file_name, col_start=1, col_end=4):\n",
    "            csv_file_path = os.path.join(csv_file_folder, csv_file_name)\n",
    "            if os.path.exists(csv_file_path):\n",
    "                csv_df = pd.read_csv(csv_file_path)\n",
    "                return csv_df.iloc[-1, col_start:col_end].values.tolist()  # Convert NumPy array to Python list\n",
    "            else:\n",
    "                print(f\"Warning: File {csv_file_name} not found.\")\n",
    "                return [\"NA\"]  # Return \"NA\" instead of an empty list\n",
    "\n",
    "        # Initialize a list to store results\n",
    "        results = []\n",
    "\n",
    "        # Process each Cohort (row) in the Excel file\n",
    "        for idx, row in excel_df.iterrows():\n",
    "            Cohort = row['Cohort']\n",
    "            print(f\"Processing Cohort: {Cohort}\")\n",
    "            \n",
    "            # Initialize the list for this Cohort\n",
    "            Cohort_results = {\n",
    "                'Cohort': Cohort,\n",
    "                'Top Sensitivity 1': 'NA',\n",
    "                'Top Accuracy 1': 'NA',\n",
    "                'Top Biomarkers 1': 'NA',\n",
    "                'Top Sensitivity 2': 'NA',\n",
    "                'Top Accuracy 2': 'NA',\n",
    "                'Top Biomarkers 2': 'NA',\n",
    "                'Top Sensitivity 3': 'NA',\n",
    "                'Top Accuracy 3': 'NA',\n",
    "                'Top Biomarkers 3': 'NA',\n",
    "                'Top Sensitivity 4': 'NA',\n",
    "                'Top Accuracy 4': 'NA',\n",
    "                'Top Biomarkers 4': 'NA',\n",
    "                'Top Sensitivity 5': 'NA',\n",
    "                'Top Accuracy 5': 'NA',\n",
    "                'Top Biomarkers 5': 'NA'\n",
    "            }\n",
    "            \n",
    "            # Generate ordered Sensitivity-Accuracy column pairs\n",
    "            sensitivity_accuracy_pairs = sorted(\n",
    "                [(f'Sensitivity {i}', f'Accuracy {i}') for i in range(1, num_combinations + 1)], \n",
    "                key=lambda x: int(x[0].split(' ')[1])  # Sort by integer value\n",
    "            )\n",
    "            \n",
    "            # Store valid sensitivity-accuracy pairs\n",
    "            valid_sensitivities = []\n",
    "            \n",
    "            for sensitivity_col, accuracy_col in sensitivity_accuracy_pairs:\n",
    "                if sensitivity_col not in row or accuracy_col not in row:\n",
    "                    continue  # Skip missing columns\n",
    "                \n",
    "                sensitivity_value = row[sensitivity_col]\n",
    "                accuracy_value = row[accuracy_col]\n",
    "                \n",
    "                # Only consider Sensitivity if Accuracy > 0.60\n",
    "                if pd.notna(accuracy_value) and accuracy_value > 0.60:\n",
    "                    # Determine which CSV file to read based on the Sensitivity number\n",
    "                    sensitivity_num = int(sensitivity_col.split(' ')[1])\n",
    "                    csv_file_name = f'FeatureVectorTissueDet{sensitivity_num}.csv'\n",
    "                    \n",
    "                    # Get selected biomarkers for the current sensitivity\n",
    "                    biomarkers = get_selected_biomarkers(csv_file_name)\n",
    "                    \n",
    "                    # Store the result\n",
    "                    valid_sensitivities.append({\n",
    "                        'Sensitivity': sensitivity_value,\n",
    "                        'Accuracy': accuracy_value,\n",
    "                        'Biomarkers': biomarkers\n",
    "                    })\n",
    "            \n",
    "            # If valid sensitivities exist, get the top 5 sorted by highest sensitivity\n",
    "            if valid_sensitivities:\n",
    "                sorted_sensitivities = sorted(valid_sensitivities, key=lambda x: x['Sensitivity'], reverse=True)[:5]\n",
    "                \n",
    "                # Update the Cohort result with the top 5 sensitivities\n",
    "                for i, res in enumerate(sorted_sensitivities):\n",
    "                    Cohort_results[f'Top Sensitivity {i + 1}'] = res['Sensitivity']\n",
    "                    Cohort_results[f'Top Accuracy {i + 1}'] = res['Accuracy']\n",
    "                    Cohort_results[f'Top Biomarkers {i + 1}'] = res['Biomarkers']\n",
    "            \n",
    "            # Append the result for the current Cohort\n",
    "            results.append(Cohort_results)\n",
    "\n",
    "        # Create a DataFrame for the results\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Ensure output path exists\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        # Define output file path\n",
    "        output_file_path = os.path.join(output_path, 'Top_5_Sensitivities.xlsx')\n",
    "\n",
    "        # Save the results to Excel\n",
    "        results_df.to_excel(output_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "        print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # Main Execution\n",
    "    # ==================================================\n",
    "\n",
    "    # Part 1: Preliminary Analysis and Formation of Average1.xlsx\n",
    "    process_clinical_data(file_path, sheet_name, biomarkers, output_dir, tumor_types, total_positive_patients, num_combinations, random_patient_range)\n",
    "\n",
    "    # Part 2: Formation of Positives1.xlsx and Sensitivity Outcomes\n",
    "    merge_positives_to_excel(output_dir, cohorts_to_analyze, num_combinations)\n",
    "    calculate_sensitivity_and_accuracy(output_dir, cohorts_to_analyze, total_positive_patients, num_combinations)\n",
    "    get_top_5_sensitivities(output_dir, cohorts_to_analyze, num_combinations)\n",
    "\n",
    "# Example usage\n",
    "file_path = r'D:\\Cancer Detection folder\\Test\\Clinical cancer data.xlsx'\n",
    "sheet_name = 'Normal and Cancer'\n",
    "biomarkers = ['Angiopoietin-2', 'CA-125', 'CA 15-3', 'CEA', 'CYFRA 21-1', 'FGF2', 'G-CSF', 'HE4', 'HGF', 'PAR', 'sPECAM-1', 'Thrombospondin-2']\n",
    "output_dir = r\"D:\\Cancer Detection folder\\Test\"\n",
    "\n",
    "# User-defined inputs\n",
    "tumor_types = {\n",
    "    'normal': 528,\n",
    "    'breast': 58,\n",
    "    'colorectum': 137,\n",
    "    'esophagus': 18,\n",
    "    'liver': 22,\n",
    "    'lung': 35,\n",
    "    'ovary': 31,\n",
    "    'pancreas': 32,\n",
    "    'stomach': 41\n",
    "}\n",
    "total_positive_patients = {\n",
    "    \"Breast\": 77, \"Colorectum\": 182, \"Esophagus\": 25, \"Liver\": 29,\n",
    "    \"Lung\": 47, \"Ovary\": 41, \"Pancreas\": 42, \"Stomach\": 55\n",
    "}\n",
    "cohorts_to_analyze = ['Breast', 'Colorectum', 'Esophagus', 'Liver', 'Lung', 'Ovary', 'Pancreas', 'Stomach']\n",
    "num_combinations = 220  # User-defined number of combinations\n",
    "random_patient_range = 1802  # User-defined random patient range\n",
    "\n",
    "# Execute the TDA_cancerDetect function\n",
    "TDAcancer_detect_2(file_path, sheet_name, biomarkers, output_dir, tumor_types, total_positive_patients, num_combinations, random_patient_range, cohorts_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5bd51-ed0d-4c30-92c0-73227bd7c832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
